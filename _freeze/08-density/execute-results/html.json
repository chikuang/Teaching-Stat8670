{
  "hash": "92f3383742c01f5fd8c2fd3779d467c0",
  "result": {
    "engine": "knitr",
    "markdown": "# Density Estimation\n\n\\newcommand{\\E}{\\mathbb E}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\var}{\\mathbb{V}ar}\n\\newcommand{\\bx}{\\mathbf{x}}\n\\newcommand{\\bX}{\\mathbf{X}}\n\\newcommand{\\cov}{\\mathbb{C}ov}\n\\newcommand{\\mse}{\\mathrm{MSE}}\n\\newcommand{\\corr}{\\mathbb{C}orr}\n\\newcommand{\\unif}{\\operatorname{Unif}}\n\\newcommand{\\geom}{\\operatorname{Geom}}\n\\newcommand{\\bet}{\\operatorname{Beta}}\n\\newcommand{\\bern}{\\operatorname{Bern}}\n\\newcommand{\\iid}{\\overset{iid}{\\sim}}\n\\newcommand{\\ef}{\\operatorname{Eff}}\n\\newcommand{\\htt}{\\hat \\theta}\n\\newcommand{\\b}{\\mathbb b}\n\n\n\nUp to now, we have discussed various statistical methods for estimating parameters, testing hypotheses, and making predictions based on observed data. However, in many real-world applications, we often encounter situations where we need to estimate the underlying probability distribution of a dataset without assuming a specific parametric form. This is where density estimation comes into play.\n\nDensity estimation is a fundamental technique in statistics that allows us to estimate the probability density function (PDF). We know that, density does not always exist!\n\nThere are two main types of density estimation methods:\n\n1. **Parametric Density Estimation**: In this approach, we assume that the data follows a specific parametric distribution (e.g., normal, exponential, etc.) and estimate the parameters of that distribution using methods like Maximum Likelihood Estimation (MLE) or Method of Moments.\n\n2. **Non-Parametric Density Estimation**: This approach does not assume any specific parametric form for the underlying distribution. Instead, it estimates the density directly from the data using techniques such as Kernel Density Estimation (KDE) or Histogram-based methods.\n\n## Kenel Density Estimation (KDE)\n\nKernel Density Estimation (KDE) is a popular non-parametric method for estimating the probability density function of a random variable. The basic idea behind KDE is to place a smooth kernel function (e.g., Gaussian, Epanechnikov, etc.) at each data point and then sum these kernels to obtain a smooth estimate of the density.\n\nThe KDE at a point $x$ is given by:\n$$\n\\hat{f}(x) = \\frac{1}{n h} \\sum_{i=1}^{n} K\\left(\\frac{x - X_i}{h}\\right),\n$$\nwhere:\n\n- $\\hat{f}(x)$ is the estimated density at point $x$,\n- $n$ is the number of data points,\n- $h$ is the bandwidth (smoothing parameter),\n- $K$ is the kernel function,\n- $X_i$ are the observed data points.\n\nProperties of KDE:\n\n- The choice of kernel function $K$ affects the smoothness of the estimated density. Common choices include Gaussian, Epanechnikov, and Uniform kernels.\n\n- The bandwidth $h$ is a crucial parameter that controls the trade-off between bias and variance in the density estimate. A smaller bandwidth leads to a more detailed estimate (lower bias, higher variance), while a larger bandwidth results in a smoother estimate (higher bias, lower variance).\n\n\n### Example of using KDE in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate sample data\nset.seed(123)\ndata <- rnorm(1000, mean = 0, sd = 1)\n# Perform Kernel Density Estimation\nkde <- density(data, bw = \"nrd0\")  # Using default bandwidth selection\n# Plot the results\nplot(kde, main = \"Kernel Density Estimation\", xlab = \"Value\", ylab = \"Density\")\n```\n\n::: {.cell-output-display}\n![](08-density_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# compare with the histogram\nplot(kde, main = \"Kernel Density Estimation\", xlab = \"Value\", ylab = \"Density\", col = \"blue\", lwd = 2)\nhist(data, probability = TRUE, breaks = 30, col = rgb(0.8, 0.2, 0.2, 0.5), add = TRUE)\nlegend(\"topright\", legend = c(\"KDE\", \"Histogram\"), col = c(\"blue\", rgb(0.8, 0.2, 0.2, 0.5)), lty = c(1, NA), pch = c(NA, 15))\n```\n\n::: {.cell-output-display}\n![](08-density_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n:::\n\n\n\n## Properties of the Kernel \n\nA kernel function $K$ must satisfy the following properties:\n\n1. **Non-negativity**: $K(u) \\geq 0$ for all $u$.\n2. **Normalization**: The integral of the kernel function over its entire domain must equal 1:\n   $$\n   \\int_{-\\infty}^{\\infty} K(u) \\, du = 1.\n   $$\n3. **Symmetry**: The kernel function should be symmetric around zero:\n   $$\n   K(u) = K(-u).\n   $$\n\n### Common Kernel Functions\n\n- **Gaussian Kernel**:\n  $$\n  K(u) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}u^2}\n  $$\n- **Epanechnikov Kernel**:\n  $$\n  K(u) = \\frac{3}{4}(1 - u^2) \\text{ for } |u| \\leq 1, \\text{ and } 0 \\text{ otherwise.}\n  $$\n- **Uniform Kernel**:\n  $$\n  K(u) = \\frac{1}{2} \\text{ for } |u| \\leq 1, \\text{ and } 0 \\text{ otherwise.}  \n  $$\n  \n  \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\n# --- Kernel functions ---\ngaussian_kernel <- function(u) {\n  (1 / sqrt(2 * pi)) * exp(-0.5 * u^2)\n}\n\nepanechnikov_kernel <- function(u) {\n  ifelse(abs(u) <= 1, 0.75 * (1 - u^2), 0)\n}\n\nuniform_kernel <- function(u) {\n  ifelse(abs(u) <= 1, 0.5, 0)\n}\n\n# Grid of points for kernels\nx_kernel <- seq(-4, 4, length.out = 400)\n\n# Data frame for kernel functions\ndf_kernel <- tibble(\n  x = x_kernel,\n  Gaussian = gaussian_kernel(x_kernel),\n  Epanechnikov = epanechnikov_kernel(x_kernel),\n  Uniform = uniform_kernel(x_kernel)\n) |>\n  pivot_longer(cols = -x, names_to = \"Kernel\", values_to = \"value\") |>\n  mutate(Type = \"Kernel function\")\n\n# --- Density estimation using different kernels ---\n\nset.seed(123)\nsample_data <- rnorm(300, mean = 0, sd = 1)  # some example data\n\ndens_gauss <- density(sample_data, kernel = \"gaussian\", n = 400)\ndens_epa   <- density(sample_data, kernel = \"epanechnikov\", n = 400)\n# 'Uniform' â‰ˆ 'rectangular' kernel in base::density()\ndens_uni   <- density(sample_data, kernel = \"rectangular\", n = 400)\n\ndf_dens <- bind_rows(\n  tibble(x = dens_gauss$x, value = dens_gauss$y, Kernel = \"Gaussian\"),\n  tibble(x = dens_epa$x,   value = dens_epa$y,   Kernel = \"Epanechnikov\"),\n  tibble(x = dens_uni$x,   value = dens_uni$y,   Kernel = \"Uniform\")\n) |>\n  mutate(Type = \"Density estimate\")\n\n# --- Combine and plot ---\n\ndf_all <- bind_rows(df_kernel, df_dens)\n\nggplot(df_all, aes(x = x, y = value)) +\n  geom_line(linewidth = 1) +\n  facet_grid(Type ~ Kernel, scales = \"free_y\") +\n  labs(\n    x = \"x or u\",\n    y = \"\",\n    title = \"Kernel Functions and Corresponding Density Estimates\"\n  ) +\n  theme_bw(base_size = 14)\n```\n\n::: {.cell-output-display}\n![](08-density_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n### Bandwidth Selection\n\nChoosing an appropriate bandwidth is critical for obtaining a good density estimate. Several methods exist for bandwidth selection, including:\n\n- **Rule of Thumb**: A simple method based on the standard deviation and sample size.\n\n- **Cross-Validation**: A data-driven approach that minimizes the integrated squared error.\n\n- **Plug-in Methods**: These methods estimate the optimal bandwidth based on the data's characteristics.\n\n### Example of Bandwidth Selection in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate sample data\nset.seed(123)\ndata <- rnorm(1000, mean = 0, sd = 1)\n# Perform KDE with different bandwidths\nkde_small_bw <- density(data, bw = 0.1)\nkde_large_bw <- density(data, bw = 1)\n# Plot the results\nplot(kde_small_bw, main = \"KDE with Different Bandwidths\", xlab = \"Value\", ylab = \"Density\", col = \"red\", lwd = 2)\nlines(kde_large_bw, col = \"green\", lwd = 2)\nlegend(\"topright\", legend = c(\"Small Bandwidth (0.1)\", \"Large Bandwidth (1)\"), col = c(\"red\", \"green\"), lty = 1)\n```\n\n::: {.cell-output-display}\n![](08-density_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nOther Kernel Functions\n\n* Epanechnikov Kernel\n* Uniform Kernel\n* Triangular Kernel\n### Example of Different Kernel Functions in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate sample data\nset.seed(123)\ndata <- rnorm(1000, mean = 0, sd = 1)\n# Perform KDE with different kernel functions\nkde_gaussian <- density(data, kernel = \"gaussian\")\nkde_epanechnikov <- density(data, kernel = \"epanechnikov\")\nkde_triangular <- density(data, kernel = \"triangular\")\n# Plot the results\nplot(kde_gaussian, main = \"KDE with Different Kernel Functions\", xlab = \"Value\", ylab = \"Density\", col = \"blue\", lwd = 2)\nlines(kde_epanechnikov, col = \"orange\", lwd = 2)\nlines(kde_triangular, col = \"purple\", lwd = 2)\nlegend(\"topright\", legend = c(\"Gaussian Kernel\", \"Epanechnikov Kernel\", \"Triangular Kernel\"), col = c(\"blue\", \"orange\", \"purple\"), lty = 1)\n```\n\n::: {.cell-output-display}\n![](08-density_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## choose different bandwidth\nkde_gaussian_bw <- density(data, kernel = \"gaussian\", bw = 0.2)\nkde_epanechnikov_bw <- density(data, kernel = \"epanechnikov\", bw = 0.2)\nkde_triangular_bw <- density(data, kernel = \"triangular\", bw = 0.2)\n# Plot the results\nplot(kde_gaussian_bw, main = \"KDE with Different Kernel Functions (bw=0.2)\", xlab = \"Value\", ylab = \"Density\", col = \"blue\", lwd = 2)\nlines(kde_epanechnikov_bw, col = \"orange\", lwd = 2)\nlines(kde_triangular_bw, col = \"purple\", lwd = 2)\nlegend(\"topright\", legend = c(\"Gaussian Kernel\", \"Epanechnikov Kernel\", \"Triangular Kernel\"), col = c(\"blue\", \"orange\", \"purple\"), lty = 1)\n```\n\n::: {.cell-output-display}\n![](08-density_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\n## Show the difference of one kernel with three bandwidths\nkde_gaussian_bw1 <- density(data, kernel = \"gaussian\", bw = 0.1)\nkde_gaussian_bw2 <- density(data, kernel = \"gaussian\", bw = 0.5)\nkde_gaussian_bw3 <- density(data, kernel = \"gaussian\", bw = 1)\n# Plot the results\nplot(kde_gaussian_bw1, main = \"Gaussian Kernel with Different Bandwidths\", xlab = \"Value\", ylab = \"Density\", col = \"red\", lwd = 2)\nlines(kde_gaussian_bw2, col = \"green\", lwd = 2)\nlines(kde_gaussian_bw3, col = \"blue\", lwd = 2)\nlegend(\"topright\", legend = c(\"Bandwidth = 0.1\", \"Bandwidth = 0.5\", \"Bandwidth = 1\"), col = c(\"red\", \"green\", \"blue\"), lty = 1)\n```\n\n::: {.cell-output-display}\n![](08-density_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n```{.r .cell-code}\n## show the underlying data\nhist(data, probability = TRUE, breaks = 30, col = rgb(0.8, 0.2, 0.2, 0.5), main = \"Histogram with KDE Overlay\", xlab = \"Value\", ylab = \"Density\")\nlines(kde_gaussian_bw1, col = \"red\", lwd = 2)\nlines(kde_gaussian_bw2, col = \"green\", lwd = 2)\nlines(kde_gaussian_bw3, col = \"blue\", lwd = 2)\nlegend(\"topright\", legend = c(\"Bandwidth = 0.1\", \"Bandwidth = 0.5\", \"Bandwidth = 1\"), col = c(\"red\", \"green\", \"blue\"), lty = 1)\n```\n\n::: {.cell-output-display}\n![](08-density_files/figure-html/unnamed-chunk-4-4.png){width=672}\n:::\n:::\n\n\n## Other ways\n\nBesides KDE, there are other methods for density estimation, including:\n\n- **Histogram-based Methods**: Dividing the data range into bins and counting the number of observations in each bin to estimate the density.\n- **Nearest Neighbor Methods**: Estimating the density based on the distance to the nearest neighbors.\n- **Spline-based Methods**: Using spline functions to create smooth density estimates.\n- **Mixture Models**: Modeling the data as a mixture of several distributions (e.g., Gaussian Mixture Models).\n\n---\n\nReference\n\n-   Wikipedia, [Density estimation](https://en.wikipedia.org/wiki/Density_estimation)\n\n-   Silverman, B.W. (1986). [Density Estimation for Statistics and Data Analysis](https://www.amazon.com/Density-Estimation-Statistics-Data-Analysis/dp/0412246201), Springer.\n\n-   University of Copenhagen, [Density Estimation](https://cswr.nrhstat.org/density)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}